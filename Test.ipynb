{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/train.csv')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the relevant columns\n",
    "selected_columns = ['id', 'comment_text', 'toxic', 'obscene', 'insult']\n",
    "new_df = df[selected_columns]\n",
    "\n",
    "# Display the first 10 rows of the new DataFrame\n",
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape\n",
    "new_df.dtypes\n",
    "new_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.describe()\n",
    "\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsums=new_df.iloc[:,2:].sum(axis=1)\n",
    "new_df['clean']=(rowsums==0)\n",
    "new_df['clean'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total no.of toxic comments\n",
    "len(new_df[new_df['toxic']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = new_df['comment_text']\n",
    "for i in range(5):\n",
    "    print(i,\"- \" + comment[i] + \"\\n Length -\" ,len(comment[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a numpy array of the length of each comment in the dataset.\n",
    "x = np.array([len(comment[i]) for i in range(comment.shape[0])])\n",
    "\n",
    "print(\"\"\"The maximum length of comment is:{} \n",
    "        \\nThe minimum length of the comment is:{} \n",
    "        \\nAnd the average length of a comment is: {}\"\"\".format(x.max(),x.min(),x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1,200,400,600,800,1000,1200,1400]\n",
    "plt.hist(x, bins=bins, color = 'Blue')\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments')       \n",
    "plt.axis([0, 1400, 0, 90000])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = new_df[['toxic',  'obscene' ,  'insult']]\n",
    "print(label.head(10))\n",
    "label = label.values\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating a list of comments with less than 400 length of words.\n",
    "trim_comments = [comment[i] for i in range(comment.shape[0]) if len(comment[i])<=400 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating a list of comments with less than 400 length of words.\n",
    "trim_comments = [comment[i] for i in range(comment.shape[0]) if len(comment[i])<=400 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_labels[:10, :]\n",
    "\n",
    "print(len(trim_comments))\n",
    "print(len(my_labels))\n",
    "print(\"Thus number of removed comments = {}\".format(159571-115910))\n",
    "\n",
    "print(len(trim_comments))\n",
    "print(my_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuation removal\n",
    "\n",
    "import string\n",
    "print(string.punctuation)\n",
    "punctuation_edit = string.punctuation.replace('\\'','') +\"0123456789\"\n",
    "print (punctuation_edit)\n",
    "outtab = \"                                         \"\n",
    "trantab = str.maketrans(punctuation_edit, outtab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Adding alphabets to the set\n",
    "for i in range(ord('a'),ord('z')+1):\n",
    "    stop_words.add(chr(i))\n",
    "print(stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming and Lemmatizing\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trim_comments)):\n",
    "    trim_comments[i] = trim_comments[i].lower().translate(trantab)\n",
    "    word_list = []\n",
    "    for word in trim_comments[i].split():\n",
    "        if not word in stop_words:\n",
    "            word_list.append(stemmer.stem(lemmatizer.lemmatize(word,pos=\"v\")))\n",
    "    trim_comments[i]  = \" \".join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comments after stop words removal, stemming and lemmatizing.\n",
    "for i in range(5):\n",
    "    print(trim_comments[i],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Applying count vectorizer\n",
    "count_vector = CountVectorizer(stop_words='english')\n",
    "\n",
    " \n",
    "tf = count_vector.fit_transform(trim_comments[:40000]).toarray()\n",
    "\n",
    "custom_stop_words_list = list(stop_words)\n",
    "count_vector = CountVectorizer(stop_words=custom_stop_words_list)\n",
    "tf = count_vector.fit_transform(trim_comments[:40000]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(matrix, target, test_proportion):\n",
    "    ratio = int(matrix.shape[0]/test_proportion)\n",
    "    X_train = matrix[ratio:,:]\n",
    "    X_test =  matrix[:ratio,:]\n",
    "    Y_train = target[ratio:,:]\n",
    "    Y_test =  target[:ratio,:]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = shuffle(tf, my_labels[:40000],3)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def evaluate_score(Y_test,predict): \n",
    "    loss = hamming_loss(Y_test,predict)\n",
    "    print(\"Hamming_loss : {}\".format(loss*100))\n",
    "    accuracy = accuracy_score(Y_test,predict)\n",
    "    print(\"Accuracy : {}\".format(accuracy*100))\n",
    "    try : \n",
    "        loss = log_loss(Y_test,predict)\n",
    "    except :\n",
    "        loss = log_loss(Y_test,predict.toarray())\n",
    "    print(\"Log_loss : {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySVC:\n",
    "    def __init__(self, C=1.0):\n",
    "        self.C = C\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0.0\n",
    "\n",
    "        learning_rate = 0.01\n",
    "        num_iterations = 1000\n",
    "\n",
    "        for _ in range(num_iterations):\n",
    "            predictions = self.predict(X)\n",
    "            errors = y - predictions\n",
    "\n",
    "            weight_gradient = -(2 / num_samples) * X.T @ errors\n",
    "            bias_gradient = -(2 / num_samples) * np.sum(errors)\n",
    "\n",
    "            self.weights -= learning_rate * weight_gradient\n",
    "            self.bias -= learning_rate * bias_gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.weights + self.bias\n",
    "\n",
    "    def threshold(self, predictions, threshold=0.5):\n",
    "        return (predictions >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_plot = ['toxic', 'obscene', 'insult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBinaryRelevance:\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        num_labels = Y_train.shape[1]\n",
    "\n",
    "        for i in range(num_labels):\n",
    "            model = self.classifier()\n",
    "            model.fit(X_train, Y_train[:, i])\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = np.zeros((X_test.shape[0], len(self.models)))\n",
    "\n",
    "        for i, model in enumerate(self.models):\n",
    "            predictions[:, i] = model.predict(X_test)\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "classifier = MyBinaryRelevance(classifier=MySVC(), require_dense=[False, True])\n",
    "classifier.fit(X_train, Y_train)\n",
    "# Save the trained model\n",
    "joblib.dump(classifier, \"svm_model.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_classifier = joblib.load(\"svm_model.joblib\")\n",
    "\n",
    "# Use the loaded model for predictions\n",
    "predictions_loaded = loaded_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scores for the loaded model\n",
    "evaluate_score(Y_test, predictions_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess the new comment similar to the training data\n",
    "new_comment = \"see my ass\"\n",
    "new_comment = new_comment.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "new_comment = \" \".join([stemmer.stem(lemmatizer.lemmatize(word, pos=\"v\")) for word in new_comment.split() if word not in stop_words])\n",
    "\n",
    "# Use the saved SVM model for prediction\n",
    "new_comment_vectorized = count_vector.transform([new_comment]).toarray()\n",
    "predictions_svm = loaded_classifier.predict(new_comment_vectorized)\n",
    "\n",
    "# Display the predictions\n",
    "for i, label in enumerate(label_plot):\n",
    "    print(f\"{label}: {predictions_svm[0, i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
